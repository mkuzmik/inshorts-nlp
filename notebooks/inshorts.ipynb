{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "\n",
    "# json pretty-printer import\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_inshorts(categories, min_items):\n",
    "    \"\"\"\n",
    "    Download stories from https://inshorts.com \n",
    "    \n",
    "    :param categories: list of categories that you want to download \n",
    "    :param min_items: minimal amount of stories per each category\n",
    "    :return: list of (story, category) touples\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for category in categories:\n",
    "        labeled = []\n",
    "        offset = ''\n",
    "        while len(labeled) < min_items:\n",
    "            downloaded = __download_for(category, offset)\n",
    "            offset = downloaded['offset']\n",
    "            labeled += downloaded['stories']\n",
    "        result += labeled\n",
    "    return result\n",
    "\n",
    "\n",
    "def __download_for(category, offset):\n",
    "    params = 'category=' + category + '&news_offset=' + offset\n",
    "    resp = __request('POST', 'https://inshorts.com/en/ajax/more_news', params)\n",
    "    obj = __load_json_safely(resp)\n",
    "    stories = {'stories': __label(__parse_stories_from(obj['html']), category), 'offset': obj['min_news_id']}\n",
    "    # pp.pprint(stories)\n",
    "    return stories\n",
    "\n",
    "\n",
    "def __label(stories, category):\n",
    "    return [{\"label\": category, \"content\": story} for story in stories]\n",
    "\n",
    "\n",
    "def __parse_stories_from(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    unflattened = [i.contents for i in soup.findAll(\"div\", {\"itemprop\": 'articleBody'})]\n",
    "    stories_list = [item for sublist in unflattened for item in sublist]\n",
    "    return stories_list\n",
    "\n",
    "\n",
    "def __request(method, url, payload):\n",
    "    headers = {\n",
    "        'Content-Type': \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        'Cache-Control': \"no-cache\",\n",
    "        'Postman-Token': \"e2290974-00cb-40d4-92f4-f9b7c8398ce8\"\n",
    "    }\n",
    "    response = requests.request(method, url, data=payload, headers=headers)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def __load_json_safely(serialized):\n",
    "    try:\n",
    "        return json.loads(serialized)\n",
    "    except JSONDecodeError:\n",
    "        print('ERROR: cannot deserialize json: ' + serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape 100 business stories and 100 sports stories. Then put them into pandas DataFrame\n",
    "\n",
    "df = pd.DataFrame(extract_inshorts(['business', 'sports'], 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle(data_frame):\n",
    "    return data_frame.sample(frac=1)\n",
    "\n",
    "\n",
    "# DataFrame shuffling. Business stories should be mixed with sport ones\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tools required for text pre-processing\n",
    "%matplotlib inline\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from functools import reduce\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "def apply_on(collection, fun):\n",
    "    mapped = list(map(lambda x: (fun(x), 1 if fun(x) != x else 0), collection))\n",
    "    is_changed = list(map(lambda x: x[1], mapped))\n",
    "    changed_count = reduce(lambda x, y: x + y, is_changed)\n",
    "    collection = list(map(lambda x: x[0], mapped))\n",
    "    return collection, changed_count\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split(' ')])\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence preprocessed ready go dog able run mile without rest buying train good idea money'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain of text pre-processing functions to apply\n",
    "applies = [\n",
    "    lambda s: s.lower(),\n",
    "    remove_accented_chars,\n",
    "    remove_special_characters,\n",
    "    lemmatize,\n",
    "    remove_stopwords\n",
    "]\n",
    "\n",
    "df.content = reduce(lambda res, fun: list(map(fun, res)), applies, df.content)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return reduce(lambda res, fun: fun(res), applies, text)\n",
    "\n",
    "\n",
    "# pre-processing example\n",
    "preprocess_text(\"This sentence should be preprocessed and ready to go. \"\n",
    "                \"Dogs are able to run over 10 miles without any rest. \"\n",
    "                \"Buying a train is not a good idea if you do not have money\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>delhi police ha arrested four people including...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>indian oil bharat petroleum nayara energy mang...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>team india standin captain rohit sharma took s...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>among regular employee india monthly average e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>pakistan crashed asia cup defeat bangladesh we...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>supreme court wednesday ruled linking person a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>pnb fraud accused mehul choksi moved cbi court...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>india organisation chemist druggist ha declare...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>talking former indian captain dhonis ability t...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ahmedabadbased ecommerce company infibeam lost...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>delhi police ha arrested four people including...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>indian oil bharat petroleum nayara energy mang...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>team india standin captain rohit sharma took s...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>among regular employee india monthly average e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>pakistan crashed asia cup defeat bangladesh we...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>supreme court wednesday ruled linking person a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>pnb fraud accused mehul choksi moved cbi court...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>india organisation chemist druggist ha declare...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>talking former indian captain dhonis ability t...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ahmedabadbased ecommerce company infibeam lost...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def transform_tfidf(data):\n",
    "    X_counts = count_vect.fit_transform(data)\n",
    "    return tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "\n",
    "X = df.content.tolist()\n",
    "y = df.label.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "def transform(test, train):\n",
    "    transformed = transform_tfidf(test + train)\n",
    "    return transformed[:len(test)], transformed[len(test):]\n",
    "\n",
    "\n",
    "X_test_transformed, X_train_transformed = transform(X_test, X_train)\n",
    "\n",
    "clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "clf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text_list):\n",
    "    clf = MultinomialNB()\n",
    "    text_transformed, X_transformed = transform(list(map(lambda text: preprocess_text(text), text_list)), X)\n",
    "    clf.fit(X_transformed, y)\n",
    "    return clf.predict(text_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STORY: Marlena is a really nice cat. Despite her young age, she has her own company with 1234 people employed\nCATEGORY: business\n\nSTORY: Marlena is a really successful cat. She won three olympic medals in swimming.\nCATEGORY: sports\n\nSTORY: The WTO now expects global merchandise trade volumes to expand by around 3.9 per cent in 2019, down from the central 4.4 per cent forecast it made in April\nCATEGORY: business\n\nSTORY: Goldman Sachs has launched its online retail bank, Marcus, for UK customers, with a savings account that offers interest of 1.5 per cent.\nCATEGORY: business\n\nSTORY: Across Europe there are around 20 players who, were they not based abroad, would be strong contenders for Argentina’s squad.\nCATEGORY: sports\n\nSTORY: The Pumas have a new head coach in Mario Ledesma and cracks are already discernible in the “home-based only” policy introduced to try to keep Argentina’s better players at home.\nCATEGORY: business\n\n"
     ]
    }
   ],
   "source": [
    "# Let's try to predict text category (whether it's rather business or sport)\n",
    "\n",
    "predictables = [\n",
    "    \"Marlena is a really nice cat. Despite her young age, she has her own company with 1234 people employed\",\n",
    "    \"Marlena is a really successful cat. She won three olympic medals in swimming.\",\n",
    "    \"The WTO now expects global merchandise trade volumes to expand by around 3.9 per cent in 2019, \"\n",
    "    \"down from the central 4.4 per cent forecast it made in April\",\n",
    "    \"Goldman Sachs has launched its online retail bank, Marcus, for UK customers, \"\n",
    "    \"with a savings account that offers interest of 1.5 per cent.\",\n",
    "    \"Across Europe there are around 20 players who, were they not based abroad, \"\n",
    "    \"would be strong contenders for Argentina’s squad.\",\n",
    "    \"swimming pool\"\n",
    "]\n",
    "\n",
    "for story, category in zip(predictables, predict(predictables)):\n",
    "    print(\"STORY: \" + story)\n",
    "    print(\"CATEGORY: \" + category + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
